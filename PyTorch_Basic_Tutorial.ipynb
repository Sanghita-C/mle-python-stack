{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3wvFylGBCmT9EFkZxRcST",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sanghita-C/mle-python-stack/blob/main/PyTorch_Basic_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PyTorch\n",
        "\n",
        "I followed a 1 hour tutorial to brush up Pytorch. Found this amazing youtube video by Zachary Huang. This notebook is simply me following along that video\n",
        "\n",
        "https://www.youtube.com/watch?v=r1bquDz5GGA"
      ],
      "metadata": {
        "id": "hORbkrq6shEd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tensor Basics"
      ],
      "metadata": {
        "id": "dRndo2z-wwur"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "pJg5Q1oZsYkT"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You have a Python list and you try tp create a tensor out of it\n",
        "\n",
        "data = [[1,2,3],[4,5,6]]\n",
        "my_tensor = torch.tensor(data)\n",
        "\n",
        "print(my_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouuicFbCw19j",
        "outputId": "ad903359-d422-493e-8bba-43e2937819a8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# you know a shape , but not the values yet - very useful for initializing model weights\n",
        "\n",
        "shape = (2,3)\n",
        "\n",
        "ones = torch.ones(shape)\n",
        "zeros = torch.zeros(shape)\n",
        "random = torch.randn(shape)\n",
        "\n",
        "print(f\"random tensor: \\n {random} \\n\")\n",
        "print(f\"ones tensor: \\n {ones} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sTi22o5xZI_",
        "outputId": "7fd7f9d3-80e8-4175-b16b-ed29189a6f5c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "random tensor: \n",
            " tensor([[-0.8462,  0.8574,  0.1167],\n",
            "        [-0.1595, -0.6895,  0.4240]]) \n",
            "\n",
            "ones tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can also create tensors by mimicing another tensor - to follow the exact shape and dtype\n",
        "\n",
        "template = torch.tensor([[1,2],[3,4]])\n",
        "\n",
        "mimic_tensor = torch.rand_like(template, dtype=torch.float)\n",
        "\n",
        "print(f\"Template tensor \\n{template}\\n\")\n",
        "print(\"Randn_like tensor: \\n\", mimic_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOOe9uG9yFlW",
        "outputId": "d23810c6-c176-47f3-da93-9c9481e512a5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Template tensor \n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "\n",
            "Randn_like tensor: \n",
            " tensor([[0.2838, 0.0106],\n",
            "        [0.6098, 0.6571]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# critical properties of a tensor - shape , type and device\n",
        "\n",
        "tensor = torch.randn(3,4)\n",
        "\n",
        "print(f\" Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype : {tensor.dtype}\")\n",
        "print(f\"Device : {tensor.device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HegHNSKRyy2x",
        "outputId": "ea68eb92-f019-4566-c5d2-3549d7425b79"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Shape of tensor: torch.Size([3, 4])\n",
            "Datatype : torch.float32\n",
            "Device : cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: The default datatype in pytorch is float - not integer : because DL heavily depends on maing tiny step changes. you can't do those changes if your matric dtype is int. So by default it. is always float"
      ],
      "metadata": {
        "id": "DGolT9I2zyw4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##AutoGrad:\n",
        "\n",
        "AutoGrad is used for automatic differentiation.\n",
        "It uses computational graph to keep track of all changes made to a variable. But for that you need **requires_grad** to be set to true."
      ],
      "metadata": {
        "id": "_hPTOVmD0Yq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[1. ,2. ], [3., 4.]])\n",
        "w = torch.tensor([[1.0],[2.0]], requires_grad = True)\n",
        "\n",
        "print(f\"Data tensor requires grad: {x.requires_grad}\")\n",
        "print(f\"Weight tensor requires grad: {w.requires_grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7aS8ezzzh3M",
        "outputId": "a2a9c6be-73fa-47d8-aa29-7ebfac605a5d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data tensor requires grad: False\n",
            "Weight tensor requires grad: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# demo for grad_fn - something that kind of shows the history of the tensor using by refering to the computation graph.\n",
        "\n",
        "x = torch.tensor([[1. ,2. ], [3., 4.]], requires_grad = True)\n",
        "y = torch.tensor([[5. ,6. ], [7., 8.]], requires_grad = True)\n",
        "\n",
        "z = x + y\n",
        "print(z.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aavmVkeE1UDo",
        "outputId": "93dd5de6-7b81-4fa3-e91a-1f4fedf72503"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<AddBackward0 object at 0x78e1286631f0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Star (*) vs At (@)"
      ],
      "metadata": {
        "id": "O_uILflk2Zrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[1,2],[3,4]])\n",
        "b = torch.tensor([[10,20],[30,40]])\n",
        "\n",
        "element_wise_produt = a * b\n",
        "print(element_wise_produt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRPWXEPz2CsE",
        "outputId": "5d1556cd-9a89-49a0-df08-898e02f27f89"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 10,  40],\n",
            "        [ 90, 160]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @ powers neural network\n",
        "\n",
        "m1 = torch.tensor([[1,2,3],[4,5,6]])\n",
        "m2 = torch.tensor([[10,20],[30,40],[50,60]])\n",
        "\n",
        "matrix_product = m1 @ m2\n",
        "print(matrix_product)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqsHXskI23zo",
        "outputId": "8b20262f-c612-4a9e-dd7c-6181bb769df6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[220, 280],\n",
            "        [490, 640]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reduction and dim"
      ],
      "metadata": {
        "id": "FrLRIc8X3Ua8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# default behavious = collapse the whole tensor\n",
        "\n",
        "scores = torch.randn(2,3)\n",
        "\n",
        "avg = scores.mean()\n",
        "print(avg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tunEq7r-3dP2",
        "outputId": "58db4a48-370c-44e0-e479-ec438ceaccb5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-0.1652)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mean along specific directions\n",
        "\n",
        "avg_along_col = scores.mean(dim = 0) # rows are collapsed\n",
        "avg_along_row = scores.mean(dim = 1) # columns are collapsed\n",
        "\n",
        "print(avg_along_col)\n",
        "print(avg_along_row)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nj9oSfDx4xae",
        "outputId": "06bef3c7-27ae-4a2a-f95f-aa932dae6394"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.5838, -0.4759,  0.5642])\n",
            "tensor([-0.8129,  0.4826])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# arg_max\n",
        "\n",
        "print(scores)\n",
        "print(scores.argmax())\n",
        "print(torch.argmax(scores)) # index of the overall maximum value in the tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fg8yyXR5FQV",
        "outputId": "19c13830-0d93-4add-9458-aac5e8c19338"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.8477, -2.1317,  0.5408],\n",
            "        [-0.3199,  1.1800,  0.5876]])\n",
            "tensor(4)\n",
            "tensor(4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(scores.argmax(dim =0)) # index of the maximum value in each column - collapsing rows\n",
        "print(scores.argmax(dim =1)) # index of the maximum value in each row - collapsing columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jBWofPfIFxx",
        "outputId": "6271f982-d393-4179-a8e0-3ba369e838ce"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1])\n",
            "tensor([2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.gather\n",
        "\n",
        "'''\n",
        " What if you want :\n",
        " - from row0, get the element at coulmn 1\n",
        " - from row2, get the element at column 0\n",
        " '''\n",
        "data = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
        "indices_to_select = torch.tensor([[0],[2],[0]])\n",
        "selected_indices = torch.gather(data, dim=1, index = indices_to_select)\n",
        "print(selected_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfCUMr5fIkGH",
        "outputId": "ee612320-e22f-4e66-e336-f0b53f0fbbc3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1],\n",
            "        [6],\n",
            "        [7]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Forward Pass using raw tensor"
      ],
      "metadata": {
        "id": "2wYQCoRWQVO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# linear regression\n",
        "\n",
        "N = 10\n",
        "# Each datapoint has 1 input feature and 1 output value\n",
        "D_in = 1\n",
        "D_out = 1\n",
        "\n",
        "#Creating input data\n",
        "X = torch.randn(N, D_in)\n",
        "\n",
        "#Create our true target labels Y using the eqution Y =2*x +1 and add some noise\n",
        "\n",
        "true_w = torch.tensor([[2.0]])\n",
        "true_b = torch.tensor(1.0)\n",
        "\n",
        "y_true = X @ true_w + true_b +torch.randn(N, D_out)*0.1\n",
        "\n",
        "\n",
        "W = torch.randn(D_in,D_out, requires_grad = True)\n",
        "b = torch.randn(1, requires_grad = True)\n",
        "\n",
        "print(f\"True weights: {true_w} \\nTrue bias: {true_b}\")\n",
        "print(f\"Initial weights: {W} \\nInitial bias: {b}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7U8fnrfP_Ep",
        "outputId": "33a93f6d-faa9-4d59-81dd-6f52553520db"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True weights: tensor([[2.]]) \n",
            "True bias: 1.0\n",
            "Initial weights: tensor([[-0.0722]], requires_grad=True) \n",
            "Initial bias: tensor([0.5781], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Forward Pass\n",
        "Y_hat = X @W + b\n",
        "print(Y_hat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuPi3fEyYvTa",
        "outputId": "7e20b785-817a-46c7-d251-b1a8e8d45df6"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6346],\n",
            "        [0.5998],\n",
            "        [0.5715],\n",
            "        [0.5710],\n",
            "        [0.6304],\n",
            "        [0.5357],\n",
            "        [0.6359],\n",
            "        [0.7218],\n",
            "        [0.6149],\n",
            "        [0.5974]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Backward pass\n",
        "loss = torch.mean((Y_hat - y_true)**2)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT1-frw9ZYJB",
        "outputId": "1f7a16bd-40de-40fa-bdcd-6f6d1e10fe08"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.0695, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we need to reduce the loss - Autgrad does the heavy lifting for us\n",
        "# Auograd will calculate gradients for all the variables for which requires_grad = True\n",
        "\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "32TOlkz_Z6H5"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Gradients for weights: {W.grad} \\nGradients for bias: {b.grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "788mCxiObsy6",
        "outputId": "767728ac-3644-447d-f036-da999adbe4eb"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradients for weights: tensor([[-2.2678]]) \n",
            "Gradients for bias: tensor([1.0998])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W.grad.zero_()\n",
        "b.grad.zero_() #we will come to grad.zero_ in the next cell"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dpmXluvdsIU",
        "outputId": "8a17f7f4-9937-4b03-ac9f-206aeb4eff60"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training using Gradient Descent ‚Åâ\n",
        "\n",
        "- Torch.no_grad() : This command tells Autograd not to track certain calculations that we want to manually track\n",
        "\n",
        "- .grad.zero_() : Resets gradients after each iteration"
      ],
      "metadata": {
        "id": "xAzCIQqjeSNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate, epochs = 0.01,100\n",
        "\n",
        "W,b = torch.randn(D_in,D_out,requires_grad=True), torch.randn(1,requires_grad = True)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #Forward pass and loss\n",
        "  y_hat = X @ W + b\n",
        "  loss = torch.mean((y_hat - y_true)**2)\n",
        "\n",
        "  #Backward pass\n",
        "  loss.backward()\n",
        "\n",
        "  #update weights\n",
        "  with torch.no_grad():\n",
        "    W -= learning_rate*W.grad\n",
        "    b -= learning_rate*b.grad\n",
        "\n",
        "    W.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"Epoch {epoch} loss: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfBXJ6uRbznt",
        "outputId": "f3bfe550-9422-4435-aa0c-00fda0f48013"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 loss: 1.3811923265457153\n",
            "Epoch 10 loss: 0.8123468160629272\n",
            "Epoch 20 loss: 0.4787147045135498\n",
            "Epoch 30 loss: 0.28299403190612793\n",
            "Epoch 40 loss: 0.16813963651657104\n",
            "Epoch 50 loss: 0.10070731490850449\n",
            "Epoch 60 loss: 0.06108848378062248\n",
            "Epoch 70 loss: 0.0377860926091671\n",
            "Epoch 80 loss: 0.02405869960784912\n",
            "Epoch 90 loss: 0.01595306769013405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Moving to professional PyTorch\n",
        "\n",
        "We updated W and b on our own. But for large neural networks, we have billions of parameters. It is not possible to manually update them, that's where PyTorch libraries come into play"
      ],
      "metadata": {
        "id": "OjFNNdb3iGpI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Linear Layer\n",
        "\n",
        "This is what performs the Y = X @ w + b"
      ],
      "metadata": {
        "id": "7XfIiK6Q1K8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "D_in = 1\n",
        "D_out = 1\n",
        "\n",
        "linear_layer = torch.nn.Linear(in_features = D_in, out_features = D_out)\n",
        "\n",
        "print(\"the weight of the model\",linear_layer.weight)\n",
        "print(\"the bias of the model\",linear_layer.bias)\n",
        "\n",
        "y_hat_nn = linear_layer(X)\n",
        "\n",
        "print(f\"Output of nn.Linear (first 3 rows): \\n {y_hat_nn[:3]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvAEZxLmgeFh",
        "outputId": "401e4864-74b4-484a-aa67-020c68773191"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the weight of the model Parameter containing:\n",
            "tensor([[0.2127]], requires_grad=True)\n",
            "the bias of the model Parameter containing:\n",
            "tensor([-0.9449], requires_grad=True)\n",
            "Output of nn.Linear (first 3 rows): \n",
            " tensor([[-1.1112],\n",
            "        [-1.0087],\n",
            "        [-0.9255]], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Activation Function"
      ],
      "metadata": {
        "id": "XfgJwxZP2crr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "relu = torch.nn.ReLU()\n",
        "sample_data = torch.tensor([[-1.0], [0.0], [1.0]])\n",
        "\n",
        "print(f\"Input data: \\n {sample_data}\")\n",
        "\n",
        "print(f\"Output of ReLU: \\n {relu(sample_data)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEWPF7YK2MYq",
        "outputId": "9a0fdc5c-5b36-4ca4-e60e-f425d8fe0306"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data: \n",
            " tensor([[-1.],\n",
            "        [ 0.],\n",
            "        [ 1.]])\n",
            "Output of ReLU: \n",
            " tensor([[0.],\n",
            "        [0.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gelu = torch.nn.GELU()\n",
        "sample_data = torch.tensor([[-1.0], [0.0], [1.0]])\n",
        "\n",
        "print(f\"Input data: \\n {sample_data}\")\n",
        "\n",
        "print(f\"Output of GELU: \\n {gelu(sample_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS8CcOOD4Rzh",
        "outputId": "b73c4c50-5f5b-4260-c70f-22899865e05d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data: \n",
            " tensor([[-1.],\n",
            "        [ 0.],\n",
            "        [ 1.]])\n",
            "Output of GELU: \n",
            " tensor([[-0.1587],\n",
            "        [ 0.0000],\n",
            "        [ 0.8413]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#softmax\n",
        "\n",
        "softmax = torch.nn.Softmax(dim =-1)\n",
        "\n",
        "logits = torch.tensor([[1.0,3.0,0.5, 1.5],[-1.0,2.0,1.0,0.0]])\n",
        "\n",
        "probabilities = softmax(logits)\n",
        "\n",
        "print(f\"Logits: \\n {logits}\")\n",
        "print(f\"Probabilities: \\n {probabilities}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBKcRSVi8ugW",
        "outputId": "99de408f-33c1-45aa-c877-ad56b630a72b"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits: \n",
            " tensor([[ 1.0000,  3.0000,  0.5000,  1.5000],\n",
            "        [-1.0000,  2.0000,  1.0000,  0.0000]])\n",
            "Probabilities: \n",
            " tensor([[0.0939, 0.6942, 0.0570, 0.1549],\n",
            "        [0.0321, 0.6439, 0.2369, 0.0871]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Embeddings\n"
      ],
      "metadata": {
        "id": "MxBzDhui94u0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10\n",
        "embedding_dim = 3\n",
        "\n",
        "embedding_layer = torch.nn.Embedding(vocab_size, embedding_dim)\n",
        "\n"
      ],
      "metadata": {
        "id": "f8wQb6py9pCh"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Layer Norm\n",
        "\n",
        "Prevents values from exploding or vanish\n",
        "\n",
        "It rescales all the values into a stable range\n"
      ],
      "metadata": {
        "id": "U40zaFkL-pm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if the input vector that needs to be stabilized has feature dimension 3, then we create norm layer of dimension 3\n",
        "norm_layer = torch.nn.LayerNorm(normalized_shape = 3)\n",
        "input_features= torch.tensor([[1.0,2.0,3.0],[4.0,5.0,6.0]])\n",
        "\n",
        "normalized_features = norm_layer(input_features)\n",
        "print(f\"Input features: \\n {input_features}\")\n",
        "print(f\"Normalized features: \\n {normalized_features}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "BkwLQfcp-shA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a03c6fb-af1d-471c-c63b-bea5e5bb8cf0"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input features: \n",
            " tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "Normalized features: \n",
            " tensor([[-1.2247,  0.0000,  1.2247],\n",
            "        [-1.2247,  0.0000,  1.2247]], grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dropout\n",
        "\n",
        "Prevents overfitting by randomly tuning neurons to zero during training"
      ],
      "metadata": {
        "id": "-OuEnIEQ0d-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropout_layer = torch.nn.Dropout(p=0.5)\n",
        "input_layer = torch.ones(1,10)\n",
        "\n",
        "#Activate Dropout Layer for training\n",
        "dropout_layer.train()\n",
        "output_train = dropout_layer(input_layer) # the input also gets scaled\n",
        "\n",
        "#Switch off drop out during test\n",
        "dropout_layer.eval()\n",
        "output_test = dropout_layer(input_layer)\n",
        "\n",
        "\n",
        "print(f\"Input layer: \\n {input_layer}\")\n",
        "print(f\"Output train: \\n {output_train}\")\n",
        "print(f\"Output test: \\n {output_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFd-bbLrx-4r",
        "outputId": "b16a9d83-0587-49ba-cd01-ffe651daea1e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input layer: \n",
            " tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
            "Output train: \n",
            " tensor([[0., 0., 2., 0., 2., 0., 0., 2., 0., 0.]])\n",
            "Output test: \n",
            " tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Professional Pytorch\n",
        "\n",
        "Main elements are -:\n",
        "\n",
        "- nn.module : for struturing all the layers of neural network\n",
        "- nn.optim : to automate the learning\n"
      ],
      "metadata": {
        "id": "MlJhchfL2QDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LinearRegressionModule ( nn.Module):\n",
        "  def __init__(self, in_feature, out_feature):\n",
        "    super().__init__() # very important\n",
        "    self.linear_layer = nn.Linear(in_feature, out_feature) # as we learnt earlier - this will do the  y = wx + b\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    y_hat = self.linear_layer(x)\n",
        "    return y_hat\n",
        "\n",
        "\n",
        "model = LinearRegressionModule(1,1)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QINVxg_L1xJV",
        "outputId": "58ac28fc-46c9-48a3-ac7b-b86141ea599a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegressionModule(\n",
            "  (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Optimizer module\n",
        "import torch.optim as optim\n",
        "learning_rate = 0.01\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
        "loss_fn = torch.nn.MSELoss()\n"
      ],
      "metadata": {
        "id": "S1dnLoXeHxTo"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "D_in = 1\n",
        "D_out = 1\n",
        "N = 10\n",
        "X = torch.randn(N, D_in)\n",
        "y_true = 2* X + 1 + torch.randn(N, D_out)*0.1\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #Forward pass\n",
        "  y_hat = model(X)\n",
        "\n",
        "  # Loss Calculation\n",
        "  loss = loss_fn(y_hat,y_true)\n",
        "\n",
        "  #Training code\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"Epoch {epoch} loss: {loss}\")"
      ],
      "metadata": {
        "id": "VmK3H_Xk3Msk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f068a80-6729-4359-bf8a-ea926b137c77"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 loss: 3.3351001739501953\n",
            "Epoch 10 loss: 2.8976895809173584\n",
            "Epoch 20 loss: 2.4963088035583496\n",
            "Epoch 30 loss: 2.133594512939453\n",
            "Epoch 40 loss: 1.8100875616073608\n",
            "Epoch 50 loss: 1.524714469909668\n",
            "Epoch 60 loss: 1.2753255367279053\n",
            "Epoch 70 loss: 1.059229850769043\n",
            "Epoch 80 loss: 0.8735106587409973\n",
            "Epoch 90 loss: 0.7151986956596375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.parameters())\n",
        "print(model.linear_layer.weight)\n",
        "print(model.linear_layer.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7Dxru3aKvyK",
        "outputId": "2426ec3e-d323-40ff-c790-335174f8e1c3"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object Module.parameters at 0x78e12a80d620>\n",
            "Parameter containing:\n",
            "tensor([[1.4388]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.7673], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tGh67dMjLBvM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}